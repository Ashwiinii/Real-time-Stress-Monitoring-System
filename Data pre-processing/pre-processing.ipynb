{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GBurgz1AaBq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/drive/MyDrive/csv_files\"\n",
        "MARKER_DATA_CSV = \"/content/drive/MyDrive/marker_info.csv\""
      ],
      "metadata": {
        "id": "oO1_g2xrAsPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_starting_times(data):\n",
        "    \"\"\"\n",
        "    Calculates all starting times for each driving period.\n",
        "    For example, Rest1: 15.13, City1: 16.00 -> Rest1: 0, City: 15.13\n",
        "    input: data (marker data)\n",
        "    \"\"\"\n",
        "    formated_data = data.copy()\n",
        "    # Starting time is 0.\n",
        "    formated_data['Rest1'] = 0\n",
        "    # Exclude columns such as drive number and total.\n",
        "    numeric_cols = data.iloc[:, 1:8].columns\n",
        "    for index, column in enumerate(numeric_cols):\n",
        "        if index == len(numeric_cols) - 1:\n",
        "            pass\n",
        "        else:\n",
        "            next_column = numeric_cols[index + 1]\n",
        "            # Calculate the time between the current col and next one.\n",
        "            formated_data[next_column] = formated_data[column] + data[column]\n",
        "    print(\"Data with Starting Times in Minutes\\n\", formated_data)\n",
        "    return formated_data"
      ],
      "metadata": {
        "id": "xhdvTvuGCJnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_starting_indices(processed_markers, drive):\n",
        "    \"\"\"\n",
        "    Gets the drive minutes for each driving periods and converts them to slices\n",
        "    for the dataframe.\n",
        "    inputs:\n",
        "        processed_markers: marker dataframe with starting times.\n",
        "        drive: drive name (str) - i.e: Drive05\n",
        "    \"\"\"\n",
        "    signals = processed_markers[processed_markers[\"Driver\"] == drive].iloc[:, 1:8]\n",
        "    # Signals are given in 15.5Hz frequency. Marker data is in Minutes.\n",
        "    signals = signals * 15.5 * 60\n",
        "    return signals.astype(int).values[0]"
      ],
      "metadata": {
        "id": "stGKjIxnCLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_data(starting_indices, row_index):\n",
        "    \"\"\"\n",
        "    Gets the row number and coverts it to a label.\n",
        "    inputs:\n",
        "        starting_indices (list) - list of ints for the slices,\n",
        "        row_index (int)\n",
        "    \"\"\"\n",
        "    relaxed = (row_index >= starting_indices[0] and row_index < starting_indices[1]) \\\n",
        "        or (row_index > starting_indices[6])\n",
        "\n",
        "    medium = (row_index >= starting_indices[2] and row_index < starting_indices[3]) \\\n",
        "        or (row_index >= starting_indices[4] and row_index < starting_indices[5])\n",
        "\n",
        "    stressed = (row_index >= starting_indices[1] and row_index < starting_indices[2]) \\\n",
        "        or (row_index >= starting_indices[3] and row_index < starting_indices[4]) \\\n",
        "        or (row_index >= starting_indices[5] and row_index < starting_indices[6])\n",
        "\n",
        "    if relaxed:\n",
        "        return 1.0\n",
        "    elif medium:\n",
        "        return 3.0\n",
        "    elif stressed:\n",
        "        return 5.0\n"
      ],
      "metadata": {
        "id": "jfjEm5ALCOPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(marker_data_path, csv_files_path):\n",
        "    # Create a new folder called preprocessed_data if it does not exist.\n",
        "    Path(csv_files_path).joinpath(\"preprocessed_data\").mkdir(parents=True, exist_ok=True)\n",
        "    # Grabs all the csv files from the path.\n",
        "    csv_files = list(Path(csv_files_path).glob(\"*.csv\"))\n",
        "    all_drives = []\n",
        "    # Keep only filenames from each path.\n",
        "    csv_files_names = [Path(f).stem for f in csv_files]\n",
        "    # Read Marker Data\n",
        "    marker_data = pd.read_csv(marker_data_path)\n",
        "    # Each column represents the time the drive was spent in that state.\n",
        "    # For example, Drive05 spent the first 15.13 minutes resting, then\n",
        "    # 16 minutes driving in the city, then 7.74 minutes driving in Highway etc.\n",
        "    processed_markers = calculate_starting_times(data=marker_data)\n",
        "    # Select only the drives that have full data.\n",
        "    selected_drives = processed_markers[\"Driver\"]\n",
        "    for drive in selected_drives:\n",
        "        if drive.lower() in csv_files_names:\n",
        "            print(\"\\n\", f\"Processing {drive}.\")\n",
        "            idx = csv_files_names.index(drive.lower())\n",
        "            data = pd.read_csv(csv_files[idx])\n",
        "            # Marker column is not needed.\n",
        "            data = data.drop(['marker-mV'], axis=1)\n",
        "            # Get the starting time for each category (rest, highway and city)\n",
        "            starting_indices = get_starting_indices(processed_markers, drive)\n",
        "            # Label the data according the driving times.\n",
        "            data['Stress'] = data.apply(\n",
        "                lambda row: label_data(starting_indices, row.name), axis=1\n",
        "            )\n",
        "            # Save data for each drive.\n",
        "            data.to_csv(f\"{csv_files_path}/preprocessed_data/{drive}.csv\", index=False)\n",
        "            data['Drive'] = drive\n",
        "            all_drives.append(data)\n",
        "    # Join all the driver data into one big dataframe.\n",
        "    all_drives_data = pd.concat(all_drives, ignore_index=True)\n",
        "    # Save the dataframe.\n",
        "    all_drives_data.to_csv(f\"{csv_files_path}/preprocessed_data/all_drives.csv\", index=False)\n",
        "    print(f\"Data saved in the {csv_files_path}/preprocessed_data directory.\")"
      ],
      "metadata": {
        "id": "c6prTYa0CQ0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data(MARKER_DATA_CSV,CSV_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV7fJm7dCeYf",
        "outputId": "430d3bcc-bbc2-41c8-955f-cf2d71a2501c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Starting Times in Minutes\n",
            "     Driver  Rest1  City1  Highway1  City2  Highway2  City3  Rest2  \\\n",
            "0  Drive05      0  15.13     31.13  38.87     44.93  52.49  67.45   \n",
            "1  Drive06      0  15.05     29.54  36.86     43.39  51.03  63.32   \n",
            "2  Drive07      0  15.04     31.27  42.23     52.06  59.70  69.85   \n",
            "3  Drive08      0  15.00     27.31  34.54     44.05  51.69  65.12   \n",
            "4  Drive09      0  15.66     34.87  43.34     48.54  55.60  68.81   \n",
            "5  Drive10      0  15.04     30.34  39.00     44.27  51.31  63.37   \n",
            "6  Drive11      0  15.02     30.83  38.26     45.41  52.37  64.09   \n",
            "7  Drive12      0  15.01     28.42  35.98     42.48  50.54  62.22   \n",
            "8  Drive15      0  15.00     27.54  34.78     40.77  47.59  59.71   \n",
            "9  Drive16      0  15.01     31.13  38.27     43.39  50.20  64.11   \n",
            "\n",
            "   TotalTime(min)  \n",
            "0           83.23  \n",
            "1           78.38  \n",
            "2           84.87  \n",
            "3           80.19  \n",
            "4           68.82  \n",
            "5           78.15  \n",
            "6           79.08  \n",
            "7           77.23  \n",
            "8           74.70  \n",
            "9           64.10  \n",
            "\n",
            " Processing Drive05.\n",
            "\n",
            " Processing Drive06.\n",
            "\n",
            " Processing Drive07.\n",
            "\n",
            " Processing Drive08.\n",
            "\n",
            " Processing Drive09.\n",
            "\n",
            " Processing Drive10.\n",
            "\n",
            " Processing Drive11.\n",
            "\n",
            " Processing Drive12.\n",
            "\n",
            " Processing Drive15.\n",
            "\n",
            " Processing Drive16.\n",
            "Data saved in the /content/drive/MyDrive/csv_files/preprocessed_data directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "non_nan_hr_values = []\n",
        "non_nan_indices = []\n",
        "\n",
        "# Read the CSV with Rpeak row indices\n",
        "rpeak_df = pd.read_csv('/content/drive/MyDrive/csv_files/HRandpeak/rpeak_Drive05.csv')\n",
        "\n",
        "# Read the CSV with HR values\n",
        "hr_df = pd.read_csv('/content/drive/MyDrive/csv_files/HRandpeak/HR_Drive05.csv')\n",
        "\n",
        "# Read the CSV with ECG data\n",
        "ecg_df = pd.read_csv('/content/drive/MyDrive/csv_files/HRandpeak/ECG_Drive05.csv')\n",
        "\n",
        "# Initialize a new DataFrame to store the result\n",
        "result_df = ecg_df.copy()\n",
        "\n",
        "# Create an 'HR' column in the result_df with NaN values\n",
        "result_df['HR'] = 'NaN'\n",
        "\n",
        "# Iterate through the rows in rpeak_df (excluding the last row)\n",
        "for index in range(len(rpeak_df) - 1):\n",
        "    rpeak_row_index = rpeak_df.loc[index, 'Rpeak']\n",
        "    hr_value = hr_df.loc[index, 'HR']\n",
        "    result_df.loc[rpeak_row_index, 'HR'] = hr_value\n",
        "    non_nan_hr_values.append(hr_value)\n",
        "    non_nan_indices.append(rpeak_row_index)\n",
        "\n",
        "if non_nan_hr_values:\n",
        "    interpolated_hr = np.interp(result_df.index, non_nan_indices, non_nan_hr_values, left=np.nan, right=np.nan)\n",
        "    result_df['HR'] = interpolated_hr\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "#result_df.to_csv('result_ecg_data16.csv', index=False)"
      ],
      "metadata": {
        "id": "aAaxFhFRCKVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#result_df['HR'] = result_df['HR'].replace('NaN', pd.NA).interpolate()"
      ],
      "metadata": {
        "id": "z7dQFEQmHn_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('result_ecg_data05_interpo.csv', index=False)"
      ],
      "metadata": {
        "id": "V1CtN78RHr5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}